<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="UTF-8">
  <title>Minimal WebGPU Raytracer</title>
  <style>
    body,
    html {
      margin: 0;
      padding: 0;
      overflow: hidden;
      height: 100%;
    }

    canvas {
      width: 100%;
      height: 100%;
      display: block;
    }
  </style>
</head>

<body>
  <canvas id="webgpu-canvas"></canvas>
  <script type="module">

    let cameraAngle = { x: 0, y: 0 }; // yaw and pitch
    let cameraDistance = 5.0;
    const target = [0, 1, 0]; // looking at the center (sphere at y=1)
    let isMouseDown = false;

    const canvas = document.getElementById('webgpu-canvas');
    canvas.addEventListener('mousedown', () => isMouseDown = true);
    canvas.addEventListener('mouseup', () => isMouseDown = false);
    canvas.addEventListener('mousemove', (e) => {
      if (isMouseDown) {
        cameraAngle.x -= e.movementX * 0.005; // invert x
        cameraAngle.y -= e.movementY * 0.005;
        cameraAngle.y = Math.max(-Math.PI / 2 + 0.01, Math.min(Math.PI / 2 - 0.01, cameraAngle.y)); // limit pitch
      }
    });

    canvas.addEventListener('wheel', (e) => {
      cameraDistance += e.deltaY * 0.01;
      cameraDistance = Math.max(1.0, Math.min(20.0, cameraDistance));
    });



    async function init() {
      const canvas = document.getElementById('webgpu-canvas');
      const adapter = await navigator.gpu.requestAdapter();
      const device = await adapter.requestDevice();
      const context = canvas.getContext('webgpu');

      const format = navigator.gpu.getPreferredCanvasFormat();
      context.configure({ device, format, alphaMode: 'opaque' });

      const uniformBuffer = device.createBuffer({
        size: 64,
        usage: GPUBufferUsage.UNIFORM | GPUBufferUsage.COPY_DST
      });

      const shaderCode = `

      struct CameraData {
        cameraPosition : vec3<f32>,
          _pad1:f32,
        targetPosition : vec3<f32>,
          _pad2:f32,
          aspectRatio : f32,
          _pad3: vec3<f32>,
      };

      @group(0) @binding(0) var<uniform> cameraData : CameraData;

      struct VertexOutput {
        @builtin(position) position : vec4<f32>,
        @location(0) uv : vec2<f32>,
      };

@vertex
fn vs_main(@builtin(vertex_index) vertexIndex : u32) -> VertexOutput {
  var pos = array<vec2<f32>, 3>(
    vec2<f32>(-1.0, -3.0),
    vec2<f32>(3.0, 1.0),
    vec2<f32>(-1.0, 1.0)
  );

  var output : VertexOutput;
  output.position = vec4<f32>(pos[vertexIndex], 0.0, 1.0);
  output.uv = (pos[vertexIndex] + vec2<f32>(1.0)) * 0.5;
  return output;
}

@fragment
fn fs_main(@location(0) uv : vec2<f32>) -> @location(0) vec4<f32> {
  let uv2 = uv * 2.0 - vec2<f32>(1.0); // screen space [-1,1]

  // Camera basis
  let forward = normalize(cameraData.targetPosition - cameraData.cameraPosition);
  let right = normalize(cross(vec3<f32>(0.0, 1.0, 0.0), forward));
  let up = cross(forward, right);

  // Assume fov 90 degrees for simplicity
  let aspect = 1.0; // canvas is square
  let sensorX = uv2.x * cameraData.aspectRatio;
  let sensorY = uv2.y;

  let rayDirection = normalize(forward + sensorX * right + sensorY * up);

  // Ray origin and direction
  let ro = cameraData.cameraPosition;
  let rd = rayDirection;

  // Sphere intersection
  let sphereCenter = vec3<f32>(0.0, 1.0, 0.0);
  let sphereRadius = 1.0;
  let oc = ro - sphereCenter;
  let a = dot(rd, rd);
  let b = 2.0 * dot(oc, rd);
  let c = dot(oc, oc) - sphereRadius * sphereRadius;
  let discriminant = b * b - 4.0 * a * c;

  var color = vec3<f32>(0.7, 0.8, 1.0); // Background color

  if (discriminant > 0.0) {
    let t = (-b - sqrt(discriminant)) / (2.0 * a);
    if (t > 0.0) {
      let hitPos = ro + t * rd;
      let normal = normalize(hitPos - sphereCenter);
      color = 0.5 * (normal + vec3<f32>(1.0));
    }
  } else {
    // Plane y=0
    let planeNormal = vec3<f32>(0.0, 1.0, 0.0);
    let t = -(ro.y) / (rd.y);
    if (t > 0.0) {
      let hitPos = ro + t * rd;
      let checker = (floor(hitPos.x) + floor(hitPos.z)) % 2.0;
      color = mix(vec3<f32>(0.8), vec3<f32>(0.3), abs(checker));
    }
  }

  return vec4<f32>(color, 1.0);
}
  `;

      const shaderModule = device.createShaderModule({ code: shaderCode });

      const bindGroupLayout = device.createBindGroupLayout({
        entries: [{
          binding: 0,
          visibility: GPUShaderStage.FRAGMENT,
          buffer: {}
        }]
      });
      const bindGroup = device.createBindGroup({
        layout: bindGroupLayout,
        entries: [{
          binding: 0,
          resource: { buffer: uniformBuffer }
        }]
      });

      const pipeline = device.createRenderPipeline({
        layout: device.createPipelineLayout({ bindGroupLayouts: [bindGroupLayout] }),
        vertex: { module: shaderModule, entryPoint: 'vs_main' },
        fragment: { module: shaderModule, entryPoint: 'fs_main', targets: [{ format }] },
        primitive: { topology: 'triangle-list' }
      });

      window.addEventListener('resize', () => {
        resizeCanvas();
      });
      resizeCanvas();
      function resizeCanvas() {
        const devicePixelRatio = window.devicePixelRatio || 1;
        canvas.width = Math.floor(canvas.clientWidth * devicePixelRatio);
        canvas.height = Math.floor(canvas.clientHeight * devicePixelRatio);

        context.configure({
          device,
          format,
          alphaMode: 'opaque'
        });
      }

      function frame() {
        //resizeCanvas();
        const encoder = device.createCommandEncoder();
        const renderPass = encoder.beginRenderPass({
          colorAttachments: [{
            view: context.getCurrentTexture().createView(),
            loadOp: 'clear',
            clearValue: { r: 0, g: 0, b: 0, a: 1 },
            storeOp: 'store'
          }]
        });

        const cosPitch = Math.cos(cameraAngle.y);
        const sinPitch = Math.sin(cameraAngle.y);
        const cosYaw = Math.cos(cameraAngle.x);
        const sinYaw = Math.sin(cameraAngle.x);

        const camX = cameraDistance * cosPitch * sinYaw;
        const camY = cameraDistance * sinPitch;
        const camZ = cameraDistance * cosPitch * cosYaw;

        const cameraPosition = [camX + target[0], camY + target[1], camZ + target[2]];
        const aspect = canvas.width / canvas.height;
        // Upload to GPU
        device.queue.writeBuffer(uniformBuffer, 0, new Float32Array([
          cameraPosition[0], cameraPosition[1], cameraPosition[2], 0.0,
          target[0], target[1], target[2], 0.0,
          aspect, 0.0, 0.0, 0.0,
        ]));

        renderPass.setPipeline(pipeline);
        renderPass.setBindGroup(0, bindGroup); // <-- this line!
        renderPass.draw(3);
        renderPass.end();

        device.queue.submit([encoder.finish()]);
        requestAnimationFrame(frame);
      }

      frame();
    }

    init();



  </script>
</body>

</html>